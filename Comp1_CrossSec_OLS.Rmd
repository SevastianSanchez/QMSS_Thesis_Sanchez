---
title: "Component 1: Multiple OLS, Interactions, Subgroups"
author: "Sevastian Sanchez"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  word_document: default
  html_document: default
---

# All Countries, Preliminary Analysis (SPI x SDGs)
SPI = Statistical Performance Index (0-100, continuous)
SDG = Sustainable Development Goals (0-100, continuous)
DI = EIU Democracy Index/Score (0-10, continuous)
log_gdppc = Log(GDP Per Capita)


```{r setup, include=FALSE}
knitr::opts_chunk$set(
  tidy = TRUE,
  tidy.opts = list(width.cutoff = 60)  # Adjust width as needed
)
```

### FIRST: Libraries, Directory & Data 

```{r include=FALSE}
# set working directory 
setwd("~/Documents/GitHub/QMSS_Thesis_Sanchez")

#load libraries 
source("packages.R")
```

### SECOND: Run function in r-script: df_years_function.R   
*[ADJUST TIME OR SKIP AND LOADING DATA FROM DIRECTORY]*

```{r eval=FALSE, include=FALSE}
#df_years2.0():[Updated Version] used for extracting all available country data (based on country_codes) from specified range of years

#load function: all available data within year range 
#source("df_years2.0_Function.R")
#specify start & end year
#merged_full <- df_years2.0(2004, 2023) 

#saving full version as CSV output 
#write.table(merged_full, file = 'data/Main CSV Outputs/merged_full_df.csv', row.names=F, sep = ",")
```

### THIRD: Load and Refine Data   
*[SKIP IF LOADING FROM DIRECTORY]*
```{r eval=FALSE, include=FALSE}
# load merged_full csv [SKIP IF YOU CHANGED YEARS ABOVE]
#merged_full <- read_csv('data/Main CSV Outputs/merged_full_df.csv')

# FILTERING FOR ALL COUNTRIES WITH ATLEAST 1 SDG VALUE 
sdg_cols <- paste0("goal", 1:17)

# Identify & remove countries where all SDG columns are NA across all years
countries_all_sdg_missing <- merged_full %>%
  group_by(country_code) %>%
  summarise(all_missing = all(if_all(all_of(sdg_cols), is.na))) %>%
  filter(all_missing) %>%
  pull(country_code)
merged_cleaned <- merged_full %>% # Removing all rows for those countries
  filter(!country_code %in% countries_all_sdg_missing) %>% 
  filter(!is.na(country_code) & !is.na(year)) # missigness is non-random (only 1 country missing all 20 years)

#saving merged CSV output 
write.table(merged_cleaned, file = 'data/Main CSV Outputs/merged_cleaned.csv', row.names=F, sep = ",")
```

### FOURTH: Load cleaned 'merged' Dataset  
*[ADJUST VARIABLES OR SKIP IF LOADING FROM CSV]*
```{r eval=FALSE, include=FALSE}
#Load final cleaned 'merged' Dataset & selecting variables 
merged_final <- read_csv("data/Main CSV Outputs/merged_cleaned.csv") %>% 
  dplyr::select(country_name, country_code, year, sdg_overall, spi_comp, sci_overall, di_score, regime_type_2, regime_type_4, regch_event, aut_ep, dem_ep, elect_dem, lib_dem, part_dem, delib_dem, egal_dem, academ_free, income_level, income_level_lab, gdp_pc, log_gdppc, gini, population, p1_use, p2_services, p3_products, p4_sources, p5_infra, goal1, goal2, goal3, goal4, goal5, goal6, goal7, goal8, goal9, goal10, goal11, goal12, goal13, goal14, goal15, goal16, goal17)

#writing final merged csv 
write.table(merged_final, file = 'data/Main CSV Outputs/merged_final_df.csv', row.names=F, sep = ",")
```

### LOAD FINAL MERGED CSV 
```{r}
#load final merged df 
merged <- read_csv("data/Main CSV Outputs/merged_final_df.csv")
```

# COMPONENT 1: COMPARING SPI & SCI X VARIABLES

## Preliminary Analysis: Correlation & Naive OLS Models [FINALIZED]

### Correlation Analysis: SPI, SCI, DI & SDG Composite Scores
*H0: Null, there is no relationship*  
*H1: there is a statistically significant relationship between overall SPI and SDG composite scores*

```{r}
# Correlation coefficients & R-squared values for SDG and SPI/SCI/DI

# SDG ~ SPI
correlation_sdg_spi <- cor(merged$sdg_overall, merged$spi_comp, use = "complete.obs")
# R-squared value
R2_sdg_spi <- correlation_sdg_spi^2

# SDG ~ SCI
correlation_sdg_sci <- cor(merged$sdg_overall, merged$sci_overall, use = "complete.obs") 
# R-squared value
R2_sdg_sci <- correlation_sdg_sci^2

# SDG ~ DI
correlation_sdg_di <- cor(merged$sdg_overall, merged$di_score, use = "complete.obs") 
# R-squared value
R2_sdg_di <- correlation_sdg_di^2

# SPI ~ DI 
correlation_spi_di <- cor(merged$spi_comp, merged$di_score, use = "complete.obs")
# R-squared value
R2_spi_di <- correlation_spi_di^2

# SCI ~ DI 
correlation_sci_di <- cor(merged$sci_overall, merged$di_score, use = "complete.obs")
# R-squared value
R2_sci_di <- correlation_sci_di^2

# pasting correlation results
paste("Correlation coefficient:" , correlation_sdg_spi, "(SDG ~ SPI),", correlation_sdg_sci, "(SDG ~ SCI),", correlation_sdg_di, "(SDG ~ DI),", correlation_spi_di, "(SPI ~ DI),", correlation_sci_di, "(SCI ~ DI)")

# pasting R-sq results
paste("R-squared value:", R2_sdg_spi, "(SDG ~ SPI),", R2_sdg_sci, "(SDG ~ SCI),", R2_sdg_di, "(SDG ~ DI),", R2_spi_di, "(SPI ~ DI),", R2_sci_di, "(SCI ~ DI)")
```
SDG ~ SPI: Correlation coefficient: 0.784880, R-squared value: 0.616037
SDG ~ SCI: Correlation coefficient: 0.646503, R-squared value: 0.417966
SDG ~ DI: Correlation coefficient: 0.672644, R-squared value: 0.452450
SPI ~ DI: Correlation coefficient: 0.676171, R-squared value: 0.4572067
SCI ~ DI: Correlation coefficient: 0.477767, R-squared value: 0.2282613

The results demonstrates that SDG performance (SDG) composite scores are most strongly associated with the Statistical Performance Index (SPI), which shows a high correlation coefficient (0.78) and explains about 62% of the variance in SDG scores. Both the Statistical Capacity Index (SCI) and the Democracy Index (DI) also exhibit moderate positive correlations with SDG scores (0.65 and 0.67, respectively), accounting for 42% and 45% of the variance. This could indicate that countries with higher statistical performance and stronger democratic institutions tend to achieve better SDG outcomes, with SPI emerging as the most influential predictor among the indices examined.

Both SPI and SCI are also positively correlated with the Democracy Index, with SPI (0.68) showing a stronger association than SCI (0.48). These findings highlight the interconnectedness of statistical capacity and governance quality, suggesting that improvements in national statistical systems and democratic governance are mutually reinforcing factors in advancing sustainable development.

**The correlation analysis provides a useful overview of the relationships between these indices, but further analysis is needed to understand the causal mechanisms and the impact of these indices on SDG outcomes.**

### NAIVE OLS Models (Component 1): Comparing SPI & SCI Variables on SDG Performance
Finding estimated impact of variables on SDG status prior to adding controls or robust SEs
```{r}
# 1. OLS for SPI and SDG - Overall 
ols_spi_naive <- lm(sdg_overall ~ spi_comp, data = merged)
summary(ols_spi_naive)

# 2. OLS for SCI and SDG - Overall 
ols_sci_naive <- lm(sdg_overall ~ sci_overall, data = merged)
summary(ols_sci_naive)

# 3. Multiple Regression with both SPI and SCI
ols_multiple_naive <- lm(sdg_overall ~ spi_comp + sci_overall, data = merged)
summary(ols_multiple_naive)

# stargazer summary table of models: ols_spi_naive, ols_sci_naive, ols_multiple_naive.
stargazer(
  ols_spi_naive, 
  ols_sci_naive, 
  ols_multiple_naive, 
  type = "html", 
  title = "Naive OLS Models: SPI & SCI x SDG",
  dep.var.caption = "Dependent Variable:",
  dep.var.labels = "SDG Composite Score",
  covariate.labels = c("SPI Composite Score", "SCI Composite Score", "Intercept"),
  column.labels = c("SPI Only", "SCI Only", "SPI + SCI"),  # <-- Model labels at the top
  omit.stat = c("f", "ser"), 
  digits = 4,
  out = "output_CSVs/naive_ols_models_sdgs_spi_sci.html"  # Save as HTML file
)

```
ols_spi_naive: 0.47806 (p-value < 0.01)  
ols_sci_naive: 0.39081 (p-value < 0.01)  
ols_multiple_naive: spi: 0.28779 (p-value < 0.01); 
                    sci: 0.15311 (p-value < 0.01)

The impact of SCI on SDG and SPI on SDG are statistically significant, in all models. SPI appears to have a greater impact on SDGs compared to that of SCI, regardless of the model. All of this is without controls or accounting multiple time periods of the same subject (i.e., countries).

### NAIVE OLS Models (Component 2): DI variable on SPI & SDG Performance 
Finding estimated impact of DI on SPI and SDG status prior to adding controls or robust SEs
```{r}
# 1. OLS for SPI and DI - Overall
ols_spi_di_naive <- lm(spi_comp ~ di_score, data = merged)
summary(ols_spi_di_naive)

# 2. OLS for SDG and DI - Overall
ols_sdg_di_naive <- lm(sdg_overall ~ di_score, data = merged)
summary(ols_sdg_di_naive)

# stargazer summary table of models: ols_spi_di_naive, ols_sdg_di_naive.
stargazer(
  ols_spi_di_naive, 
  ols_sdg_di_naive, 
  type = "html", 
  title = "Naive OLS Models: DI & SPI/SDG",
  dep.var.caption = "Dependent Variable:",
  dep.var.labels = c("SDG Composite Score", "SPI Composite Score"),
  #covariate.labels = c("di_score", "Intercept"),
  #column.labels = c("SPI Only", "SCI Only", "SPI + SCI"),  # <-- Model labels at the top
  omit.stat = c("f", "ser"), 
  digits = 4,
  out = "output_CSVs/naive_ols_models_sdgs&spi_di.html"  # Save as HTML file
)

```
*results*
ols_spi_di_naive: 5.0122 (p-value < 0.001)
ols_sdg_di_naive: 3.22301 (p-value < 0.001)

The naive OLS models indicate that the Democracy Index (DI) has a strong positive relationship with both the Statistical Performance Index (SPI) and the Sustainable Development Goals (SDG) composite scores. The coefficients suggest that a one-unit increase in DI is associated with a 5.0122 increase in SPI and a 3.22301 increase in SDG scores, both statistically significant at p < 0.001. This suggests that countries with higher democracy scores tend to have better statistical performance and SDG outcomes.

### Checking for Heteroskedasticity: residual plots [no need to report]
```{r}
#residual plots 
plot(ols_spi_naive, which = 1)  # SDG ~ SPI model
plot(ols_sci_naive, which = 1)  # SDG ~ SCI model
plot(ols_multiple_naive, which = 1)  # SDG ~ SPI + SCI model 
plot(ols_spi_di_naive, which = 1)  # SPI ~ DI model 
plot(ols_sdg_di_naive, which = 1)  # SDG ~ DI model 

# U-shaped residuals detected, suggests non-linearity of x-variable terms. Additional tests reconfirm non-linearity (See Breusch-Pagan Test below). 
```

----------------------------------------------------------------------------------------------------------------

## TEST 1: Pooled OLS & Clustered Robust Standard Errors [COMPARING MEASURES]

*Methodology: Pooled OLS Models & Clustered Robust (Huber-White) Standard Errors*
All variables of statistical capacity (SPI & SCI) will be compared on a base pooled OLS regression model structure. Pooled OLS recognizes the panel-like structure allowing to index by specific country and year (country-year). Regular OLS, assumes independence of observations which is not suitable given the repeated waves of country-year over the course of multiple consecutive years. Furthermore, it is customary to apply clustered-group robust standard errors to account for heteroskedasticity and within-unit correlation of countries over many time points. 

*H0: Null, there is no relationship between SPI and SDG composite scores*
*H1: There is a statistically significant relationship between SPI and SDG composite scores*

```{r}
# 1. OLS for SPI and SDG - Overall 
ols_spi <- plm(formula = sdg_overall ~ spi_comp + di_score + log_gdppc + factor(year), 
               model = "pooling", 
               index = c("country_code", "year"),
               data = merged)
summary(ols_spi, vcov = vcovHC(ols_spi, cluster = "group", type = "HC1"))

# 2. OLS for SCI and SDG - Overall 
ols_sci <- plm(formula = sdg_overall ~ sci_overall + di_score + log_gdppc + factor(year), 
               model = "pooling", 
               index = c("country_code", "year"),
               data = merged)
summary(ols_sci, vcov = vcovHC(ols_sci, cluster = "group", type = "HC1"))

# 3. Multiple Regression with both SPI and SCI
ols_multiple <- plm(formula = sdg_overall ~ spi_comp + sci_overall + di_score + log_gdppc + factor(year),
               model = "pooling", 
               index = c("country_code", "year"),
               data = merged)
summary(ols_multiple, vcov = vcovHC(ols_multiple, cluster = "group", type = "HC1"))
```

### Creating dataframe combining summary and Robust SE results 
```{r echo=FALSE}
# For model statistics extraction 
summary_spi <- summary(ols_spi)
summary_sci <- summary(ols_sci)
summary_multiple <- summary(ols_multiple)

# Extracting robust SEs and coefficients (using coeftest)
rob_stats_spi <- coeftest(ols_spi, vcov = vcovHC(ols_spi, cluster = "group", type = "HC1"))
rob_stats_sci <- coeftest(ols_sci, vcov = vcovHC(ols_sci, cluster = "group", type = "HC1"))
rob_stats_multiple <- coeftest(ols_multiple, vcov = vcovHC(ols_multiple, cluster = "group", type = "HC1"))

# Stargazer Table
stargazer(ols_spi, ols_sci, ols_multiple,
          se = list(rob_stats_spi[,2], rob_stats_sci[,2], rob_stats_multiple[,2]),
          title = "Pooled OLS Models with Robust Standard Errors",
          align = TRUE,
          dep.var.labels = "SDG Overall Performance",
          covariate.labels = c("SPI Composite", "SCI Overall", "Democracy Index", 
                               "Log GDP per Capita", "Year 2008", "Year 2010", "Year 2011", 
                               "Year 2012", "Year 2013", "Year 2014", "Year 2015", "Year 2016", 
                               "Year 2017", "Year 2018", "Year 2019", "Year 2020", "Year 2021", 
                               "Year 2022", "Year 2023"),
          column.labels = c("M1: ols_spi", "M2: ols_sci", "M3: ols_multiple"),
          keep.stat = c("n", "rsq", "adj.rsq"),
          type = "html", 
          out = "output_CSVs/pooled_ols_models_spi_sci_both.html") #saved as html

# CREATING CSV OF MODEL'S STATISTICS TO SAVE 
#SPI Statistics DF
spi_df <- data.frame(
  model = rep("M1: ols_spi", nrow(rob_stats_spi)),
  term = rownames(rob_stats_spi),
  estimate = rob_stats_spi[, 1],
  std.error = rob_stats_spi[, 2],
  t.statistic = rob_stats_spi[, 3],
  p.value = rob_stats_spi[, 4],
  residual.SE = rep(sqrt(sum(residuals(ols_spi)^2) / ols_spi$df.residual), nrow(rob_stats_spi)),
  r.squared = rep(as.numeric(summary_spi$r.squared["rsq"]), nrow(rob_stats_spi)),
  adj.r.squared = rep(as.numeric(summary_spi$r.squared["adjrsq"]), nrow(rob_stats_spi)),
  row.names = NULL
)

#SCI Statistics DF
sci_df <- data.frame(
  model = rep("M2: ols_sci", nrow(rob_stats_sci)),
  term = rownames(rob_stats_sci),
  estimate = rob_stats_sci[, 1],
  std.error = rob_stats_sci[, 2],
  t.statistic = rob_stats_sci[, 3],
  p.value = rob_stats_sci[, 4],
  residual.SE = rep(sqrt(sum(residuals(ols_sci)^2) / ols_sci$df.residual), nrow(rob_stats_sci)),
  r.squared = rep(as.numeric(summary_sci$r.squared["rsq"]), nrow(rob_stats_sci)),
  adj.r.squared = rep(as.numeric(summary_sci$r.squared["adjrsq"]), nrow(rob_stats_sci)),
  row.names = NULL
)

#Combined Mod Statistics DF
multiple_df <- data.frame(
  model = "M3: ols_multiple",
  term = rownames(rob_stats_multiple),
  estimate = rob_stats_multiple[, 1],
  std.error = rob_stats_multiple[, 2],
  t.statistic = rob_stats_multiple[, 3],
  p.value = rob_stats_multiple[, 4],
  residual.SE = rep(sqrt(sum(residuals(ols_multiple)^2) / ols_multiple$df.residual), nrow(rob_stats_multiple)),
  r.squared = rep(as.numeric(summary_sci$r.squared["rsq"]), nrow(rob_stats_multiple)),
  adj.r.squared = rep(as.numeric(summary_sci$r.squared["adjrsq"]), nrow(rob_stats_multiple)),
  row.names = NULL
)

# Bind all together into one tidy dataframe
robust_mods_df <- bind_rows(spi_df, sci_df, multiple_df)

# Attributes under column names 
attr(robust_mods_df$std.error, "label") <- "Robust Std. Errors Adjusted"
attr(robust_mods_df$t.statistic, "label") <- "Robust Std. Errors Adjusted"
attr(robust_mods_df$p.value, "label") <- "Robust Std. Errors Adjusted"

#save to output_CSVs folder
write.csv(robust_mods_df, file = "output_CSVs/ols_mods_results.csv")

# View the result
print(robust_mods_df)

# DT for readability
#datatable(robust_mods_df, options = list(pageLength = 10, autoWidth = TRUE))

```
The results of the OLS models with robust standard errors indicate that both SPI and SCI have a statistically significant positive relationship with SDG composite scores. The p-values for both SPI and SCI are less than 0.001, indicating strong evidence against the null hypothesis of no relationship for either model. Holding all else constant (log GDP per capita, democracy score and year), SPI and SCI exhibit positive moderate and statistically significant relationships with SDG status.

ols_spi: 0.28735 (p-value < 0.001)*** 
ols_sci: 0.237633 (p-value < 0.001)*** 
ols_multiple: 
  spi: 0.124233 (p-value < 0.05)*
  sci: 0.138766 (p-value < 0.01)**

When compared in separate models, SPI has a greater impact on SDG status (0.28735) than SCI (0.237633). This suggests that a one-unit increase in SPI is associated with a larger improvement in SDG outcomes compared to a one-unit increase in SCI, holding all controls constant. 

Interestingly, the opposite holds true in a multiple regression model containing both SPI and SCI. SPI's impact on SDG status (0.124233) (net of SPI) is less than that of SCI's (0.138766) (net of SCI), holding all controls constant. When together, the coefficients represent the unique impact of each predictor variable (measures of statistical capacity) on SDG status, net of all other variables.

Model 1 (ols_spi) does not control for SCI and model 2 (ols_sci) does not control for spi -- this is okay. SPI is the predecessor of the SCI, sharing/data overlap, and so it is expected to have significant statistical correlation (multicollinearity). This is possibly what explains the reduction of both regression coefficients in model 3: 0.28735 to 0.124233 for SPI (__% decrease); and from 0.237633 to 0.138766 for SCI (__% decrease). This indicates that both variables capture much of the same underlying relationship with SDG performance.

However, the fact that both SPI and SCI remain significant when included together (model 3), although SCI less so than SPI, with a high adjusted R-sq (0.741525), which suggests they capture different dimensions of statistical capacity that independently contribute to SDG status.

### Checking for Multicolinearity: VIF of SPI & SCI 
```{r}
# Check correlation between SPI and SCI
cor(merged$spi_comp, merged$sci_overall, use = "complete.obs")

# Check VIF (Variance Inflation Factor) in Model 3
vif(ols_multiple)

#make into Datatable 
vif_vals <- vif(ols_multiple)   # returns a named vector
tidy_vif <- enframe(vif_vals, name = "term", value = "vif")
print(tidy_vif)
```

**colinearity:** The correlation between SCI and SPI is about 0.8277. When placed within the same model, SCI inflated the standard error of SPI from 0.013079 to 0.027054. SCI had a similar reaction from the SPI with its standard error increasing from 0.0095864 to 0.024096.


**VIF:** Such multicollinearity is moderately reflected in the VIF test which accounts for all x variables in the model instead of just the two measures of statistical capacity (SCI & SPI).

_VIF Results:_
  term          vif    Df    GVIF^(1/(2*Df))
spi_comp     4.316894  1        2.077714
sci_overall  3.754613  1        1.937682
di_score     1.598314  1        1.264244
log_gdppc    1.485085  1        1.218641
factor(year) 1.302733  4        1.033611 

Overall there reveals no severe multicollinearity (all GVIF < 5). There is moderate correlation between statistical capacity measures (spi_comp and sci_overall) with SPI moderately inflated by a factor of 4.32 and SCI inflated by a factor of  3.75. Nevertheless, it is acceptable to include both in the same model as doing so will not severely impact estimates with both factors less than 5.0. Even so, there are significant limitations in either model that warrant strong consideration, including sample size, and longitudinal suitability. All other variables show minimal multicollinearity concerns.

### Checking for Heteroskedasticity: Breusch-Pagan Test [DONE]
This validates the need for integrating robust standard errors in our models
```{r}
#Breusch-Pagan tests 
bptest(ols_spi)
bptest(ols_sci)
bptest(ols_multiple)

#make into objects 
bp_spi <- bptest(ols_spi)
bp_sci <- bptest(ols_sci)
bp_multiple <- bptest(ols_multiple)

# combine for data frame 
bp_tests <- list(
  ols_spi = bp_spi,
  ols_sci = bp_sci,
  ols_multiple = bp_multiple
)

# Tidy all tests and add a "model" column
df_bptests <- bp_tests %>% 
  map_df(~ tidy(.x), .id = "model")

df_bptests

write.table(df_bptests, file = 'output_CSVs/df_bptests_heterosked.csv', row.names=F, sep = ",")
```
Model:         BP statistic      p-value
ols_spi           207.         = 7.05e-39       
ols_sci           86.6         = 4.22e-12
ols_multiple      31.1         = 1.33e- 4 

The Breusch-Pagan Test was applied to test to see whether residuals are constant across observations, which signals unaccounted non-linear relationships, especially with macro factors such as GDP Per Capita and Population in the models. This is important because Ordinary Least Squares models assume constant error variance. In such a complex world of diverse cultural and ever-changing political structures across almost 200 countries, cross-national data, especially in development, is rarely ever linear. Accordingly, this test evaluates the extent of such non-linearity among specified predictors. 

As such, results indicate strong evidence of heteroskedasticity in all three models. The small p-values in all models indicates that the variance of residuals are not constant across observations in all three models. This reinforces the motivation behind applying robust standard errors, which have been integrated to all OLS models. Without Robust SEs, there is a risk of inflated t-statistics, leading to false significance and misinterpretation of results.

Despite the improvement from 206.5 (SPI) and 86.6 (SCI) to 31.1 (Both), there still remains statically significant heteroskedasticity in the combined model. Both statistical capacity measures create a better-specified model (ols_multiple), though not enough to eliminate heteroskedasticity entirely.

### Checking for Non-Linearity and general omitted interactions [needs regular ols models not PLM =  FIX LATER]
```{r}
#FIX LATER 
#lm test package 
resettest(ols_spi, power = 2:3, type = "fitted")
resettest(ols_sci, power = 2:3, type = "fitted")
resettest(ols_multiple, power = 2:3, type = "fitted")
```
The Ramsey RESET test for model misspecification highlights that all three models (SPI, SCI, and Multiple) exhibit significant signs of misspecification. Specifically, the p-values for the RESET test are all less than 0.001, indicating strong evidence against the null hypothesis of no misspecification. This suggests that the models do not adequately capture the relationship between the predictors and the SDG composite scores due to the existence of non-linear or combined functional form factors. Such is not limited to omitted variables, non-linear or high order polynomial relationships, or other forms of model misspecification.

Given the high variablility of statistical capacity measures and control variables like GDP per capita, misspecification is possibly the result of omitted interaction terms or heteroskedasticity (Appendix X).

### Missing Data Structure & Interpretations 
**Systematic, non-random missing data pattern:** SPI has near complete country data coverage (165 out of 168 countries with an SDG score), but with a stubborn temporal limitation (2016-2023). On the other hand, SCI has longer temporal coverage (2004-2020) but lacks reporting on high-income countries focusing primarily on the developing world (123 out of 168 countries with an SDG score).

### AIC/BIC Checking Fit
*H0: Null, SCI model > SPI model; combined model > SPI model*
*H1: SPI model > SCI model & combined model*
```{r}
# switching to lm for AIC & BIC tests 
ols_spi_lm <- lm(sdg_overall ~ spi_comp + di_score + log_gdppc + factor(year), data = merged)
ols_sci_lm <- lm(sdg_overall ~ sci_overall + di_score + log_gdppc + factor(year), data = merged)
ols_multiple_lm <- lm(sdg_overall ~ spi_comp + sci_overall + di_score + log_gdppc + factor(year), data = merged)

# Compare all three models with AIC
AIC(ols_spi_lm, ols_sci_lm, ols_multiple_lm)

# Compare all three models with BIC
BIC(ols_spi_lm, ols_sci_lm, ols_multiple_lm)

# INTO DATAFRAME 
aic_vals <- c(
  AIC(ols_spi_lm),
  AIC(ols_sci_lm),
  AIC(ols_multiple_lm)
)

bic_vals <- c(
  BIC(ols_spi_lm),
  BIC(ols_sci_lm),
  BIC(ols_multiple_lm)
)

# Model names
model_names <- c("ols_spi", "ols_sci", "ols_multiple")

# Combine into a dataframe
aic_bic_ols_results <- data.frame(
  model = model_names,
  AIC = aic_vals,
  BIC = bic_vals
)

print(aic_bic_ols_results)

# saving to output_CSVs
write.csv(aic_bic_ols_results, file = "output_CSVs/aic_bic_ols_results.csv")
```
**AIC/BIC Results**
     model          AIC       BIC
m1: ols_spi       7382.060  7443.496
m2: ols_sci       9003.178  9093.672
m3: ols_multiple  3292.001  3335.405
note: all models have different number of observations, ols_multiple containing the least.

**Adjusted R-squares** 
##[CONTINUE FROM HERE DOWN]
m3: ols_spi:      0.7757 [best fit]
m2: ols_sci:      0.74152
m1: ols_multiple: 0.75683

## Selecting Best Model
**Best fit: ols_spi (Adj Rsq: 0.7725) (AIC/BIC: 7382.060, 7443.496) (n=1082)**
Model 3 (ols_multiple) sacrifices a significant portion of its sample size in order to include both statistical capacity measures. While ols_multiple appears to outperform the other two models, the lower AIC/BIC partially reflects its smaller sample size, not necessarily a better model fit. Model 1 (ols_spi) provides better country coverage and sustains slightly higher explanatory power than model 3 (adj.r.squared: 0.7757 > 0.75683).

**Selecting model:** This analysis is specifically focused on overall statistical capacity rather than comparisons of measures. Model 1 (ols_spi) reveals a better adjusted R-squares value than that of model 2 (Adj Rsq: 0.7757 > 0.74152) and model 3 (Adj Rsq: 0.7757 > 0.75683). Model 3, containing both SPI and SCI, has greater explanatory power than model 2 (AIC/BIC: 3292.001, 3335.405 < 7382.060, 7443.496), but as mentioned, has a much smaller sample size, which significantly impedes results. Models 1 and 2 have significantly more country-year data points (n=1236 and n=1515, respectively) for regression analysis compared to model 3 (n=567). With all else considered, this study employs the Statistical Performance Index (SPI) as the primary measure of statistical capacity. 

### Visual Analysis of Fit: SCI & SPI x SDG
```{r echo=FALSE}
#define regression line colors
spi_line <- "steelblue4"
sci_line <- "darkgoldenrod"

# Creating scatterplot with both SPI and SCI on the same plot
Compare_fit <- ggplot(merged, aes(x = spi_comp, y = sdg_overall))+
  geom_smooth(aes(x = spi_comp, y = sdg_overall), 
              color = spi_line, 
              method = "lm", 
              linewidth = 0.75, 
              se = FALSE)+ # Regression line SPI
  geom_smooth(aes(x = sci_overall, y = sdg_overall), 
              color = sci_line, 
              method = "lm", 
              linewidth = 0.75, 
              se = FALSE)+ # Regression line for SCI
  geom_point(aes(color = "spi_comp"), alpha=0.50, size = 0.5)+ # Scatter plot for SPI
  geom_point(aes(x = sci_overall, y = sdg_overall, color = "sci_overall"), 
             alpha=0.5, size = 0.5)+ # Add SCI points w/different color
  scale_color_manual(values = c("spi_comp" = "steelblue1", 
                                "sci_overall" = "darkgoldenrod1")) +
  labs(title = "Comparing SPI & SCI Measures Against SDG Index",
       x = "SPI & SCI Scores (0-100)",
       y = "SDG Composite Scores (0-100)",
       color = "Statistical Capacity Measure") +  # Title for legend
  theme_bw() # Optional: adds a clean, black and white theme

Compare_fit

#make interactive
#ggplotly(Compare_fit)

# Save to specific folder
ggsave("figures/spi_sci_plot.png", Compare_fit, width = 10, height = 6)
```
The SPI regression line is expected to appear higher in terms of SDG Score compared the SCI model because SPI countries include higher-income countries. As previously mentioned, the SCI soley focuses on lower to upper-middle income countries (146 countries over 17 years). 

# INTERACTIONS AND SUBGROUP ANALYSIS

## TEST 2: Checking for Interactions [REDO RESULTS FOR ROBUST SEs]: 
- Is there a need for subgroup analysis, and if so, by what kind of group? 
- Possible Moderators: GNI Classification (income_level), regime_type_2, regime_type_4, di_score
```{r}
merged_2015 <- merged %>% 
  filter(year > 2015) %>% 
  mutate(regime_type_2 = as.factor(regime_type_2), 
         regime_type_4 = as.factor(regime_type_4))

# Interaction 1: 
# H0: NUll, there is no interaction between x (spi) & y (sdg) by income_level
# H1: GNI Classification (income_level) Interacts with the relationship between x (spi) & y (sdg)? 
inc_lev_interaction <- lm(sdg_overall ~ spi_comp*income_level + di_score + log_gdppc + factor(year), data = merged_2015)
summary(inc_lev_interaction, vcov = vcovHC(inc_lev_interaction, cluster = "group", type = "HC1"))
# [All interactions ARE significant]

# Interaction 2: 
# H0: NUll, there is no interaction between x (spi) & y (sdg) by regime type (regime_type_2)
# H1: regime type (regime_type_2) interacts with the relationship between x (spi) & y (sdg)?
reg_type2_interaction <- lm(sdg_overall ~ spi_comp*regime_type_2 + log_gdppc + factor(year), data = merged_2015)
summary(reg_type2_interaction, vcov = vcovHC(reg_type2_interaction, cluster = "group", type = "HC1"))
# [Interaction is NOT significant]

# Interaction 3: 
# H0: NUll, there is no interaction between x (spi) & y (sdg) by regime type (regime_type_4)
# H1: regime type (regime_type_4) interacts with the relationship between x (spi) & y (sdg)?
reg_type4_interaction <- lm(sdg_overall ~ spi_comp*regime_type_4 + log_gdppc + factor(year), data = merged_2015)
summary(reg_type4_interaction, vcov = vcovHC(reg_type4_interaction, cluster = "group", type = "HC1"))
# [Interactions are NOT significant, other than spi_comp:regime_type_41 (p = 0.048704)]

# Interaction 4: 
# H0: NUll, there is no interaction between x (spi) & y (sdg) by democracy level (di_score)
# H1: Democracy level (di_score) interacts with the relationship between x (spi) & y (sdg)?
reg_type_di_interaction <- lm(sdg_overall ~ spi_comp*di_score + log_gdppc + factor(year), data = merged_2015)
summary(reg_type_di_interaction, vcov = vcovHC(reg_type_di_interaction, cluster = "group", type = "HC1"))
# [Interactions are NOT significant]
```
*Interaction 1: GNI Income Classification: Yes* All GNI classifications (High, Upper-Middle, Lower-Middle, and Low) exhibit statistically significant interactions affecting the relationship between SPI and SDG performance. The significant interaction terms for each income level suggest the relationship SPI and SDG performance varies across different GNI classifications of countries.

*Interaction 2: RoW Binary Regime Type (2 options): No* there's no statistically significant interactions found from RoW regime type classifications (autocracy vs democracy) that affects the relationship between spi and sdgs.

*Interaction 3: RoW Categorical Regime type (4 options): Yes* there is one statistically significant interaction found within RoW's regime type classifications, specifically ____ (p < 0.05*). For the rest, there's no statistically significant interactions found based on RoW regime type classifications (Closed autocracy, electoral autocracy, electoral democracy, liberal democracy[FIGURE OUT WHICH ONE IS SIGNIFICANT]) that affects the relationship between SPI and SDG performance. 

*Interaction 4: Continuous di_score [0-1] Regime type: No* there are no statistically significant interactions found from regime type (infinate between 0-10) that affects the relationship between spi and sdgs. 

## Interactions DF
```{r eval=FALSE, include=FALSE}
################ in a table #################
ct <- coeftest(reg_type_di_interaction, vcov = vcovHC(reg_type_di_interaction, type = "HC1"))

# Convert to tidy dataframe
ct_tidy <- tidy(ct)

# In stargazer 
stargazer(ct_tidy, type = "text", summary = FALSE, rownames = FALSE)

# In tidy table 
ct_tidy
```

## TEST 3: WB GNI Classifications: income_level ("H", "UM", "LM", "L") 
**Disaggregated/Grouped by Development Status:** Make 4 regression models and then put them all together in a table to compare the slopes and R-sq values.
```{r}
# 1. Overall model (all countries)
overall_lm <- lm(sdg_overall ~ spi_comp + di_score + log_gdppc + population + factor(year),
                        data = merged_2015)
#summary(overall_lm)
coeftest(overall_lm, vcov = vcovHC(overall_lm, type = "HC1")) #Robust SE

# 2. High income countries
high_inc_lm <- lm(sdg_overall ~ spi_comp + di_score + log_gdppc + population + factor(year),
                        data = merged_2015 %>% 
                          filter(income_level == "H"))
#summary(high_inc_lm)
coeftest(high_inc_lm, vcov = vcovHC(high_inc_lm, type = "HC1")) #Robust SE

# 3. Upper-middle income countries
upper_mid_lm <- lm(sdg_overall ~ spi_comp + di_score + log_gdppc + population + factor(year),
                         data = merged_2015 %>% 
                           filter(income_level == "UM"))
#summary(upper_mid_lm)
coeftest(upper_mid_lm, vcov = vcovHC(upper_mid_lm, type = "HC1")) #Robust SE

# 4. Lower-middle income countries
lower_mid_lm <- lm(sdg_overall ~ spi_comp + di_score + log_gdppc + population + factor(year),
                         data = merged_2015 %>% 
                           filter(income_level == "LM"))
#summary(lower_mid_lm)
coeftest(lower_mid_lm, vcov = vcovHC(lower_mid_lm, type = "HC1")) #Robust SE

# 5. Low income countries
low_inc_lm <- lm(sdg_overall ~ spi_comp + di_score + log_gdppc + population + factor(year),
                       data = merged_2015 %>% 
                         filter(income_level == "L"))
#summary(low_inc_lm)
coeftest(low_inc_lm, vcov = vcovHC(low_inc_lm, type = "HC1")) #Robust SE
```

# GNI Classifications DF
```{r echo=FALSE}
# 1. Overall model
overall_ct <- coeftest(overall_lm, vcov = vcovHC(overall_lm, type = "HC1"))
overall_df <- data.frame(
  model = "overall_lm",
  term = rownames(overall_ct),
  estimate = overall_ct[, "Estimate"],
  std.error = overall_ct[, "Std. Error"],
  t.statistic = overall_ct[, "t value"],
  p.value = overall_ct[, "Pr(>|t|)"],
  n = nobs(overall_lm)
)

# 2. High income countries
high_inc_ct <- coeftest(high_inc_lm, vcov = vcovHC(high_inc_lm, type = "HC1"))
high_inc_df <- data.frame(
  model = "high_inc_lm",
  term = rownames(high_inc_ct),
  estimate = high_inc_ct[, "Estimate"],
  std.error = high_inc_ct[, "Std. Error"],
  t.statistic = high_inc_ct[, "t value"],
  p.value = high_inc_ct[, "Pr(>|t|)"],
  n = nobs(high_inc_lm)
)

# 3. Upper-middle income countries
upper_mid_ct <- coeftest(upper_mid_lm, vcov = vcovHC(upper_mid_lm, type = "HC1"))
upper_mid_df <- data.frame(
  model = "upper_mid_lm",
  term = rownames(upper_mid_ct),
  estimate = upper_mid_ct[, "Estimate"],
  std.error = upper_mid_ct[, "Std. Error"],
  t.statistic = upper_mid_ct[, "t value"],
  p.value = upper_mid_ct[, "Pr(>|t|)"],
  n = nobs(upper_mid_lm)
)

# 4. Lower-middle income countries
lower_mid_ct <- coeftest(lower_mid_lm, vcov = vcovHC(lower_mid_lm, type = "HC1"))
lower_mid_df <- data.frame(
  model = "lower_mid_lm",
  term = rownames(lower_mid_ct),
  estimate = lower_mid_ct[, "Estimate"],
  std.error = lower_mid_ct[, "Std. Error"],
  t.statistic = lower_mid_ct[, "t value"],
  p.value = lower_mid_ct[, "Pr(>|t|)"],
  n = nobs(lower_mid_lm)
)

# 5. Low income countries
low_inc_ct <- coeftest(low_inc_lm, vcov = vcovHC(low_inc_lm, type = "HC1"))
low_inc_df <- data.frame(
  model = "low_inc_lm",
  term = rownames(low_inc_ct),
  estimate = low_inc_ct[, "Estimate"],
  std.error = low_inc_ct[, "Std. Error"],
  t.statistic = low_inc_ct[, "t value"],
  p.value = low_inc_ct[, "Pr(>|t|)"],
  n = nobs(low_inc_lm)
)

# Combine all results
gni_classes_ols <- bind_rows(
  overall_df,
  high_inc_df,
  upper_mid_df,
  lower_mid_df,
  low_inc_df
)

attr(gni_classes_ols $std.error, "label") <- "Robust Std. Errors Adjusted"
attr(gni_classes_ols $t.statistic, "label") <- "Robust Std. Errors Adjusted"
attr(gni_classes_ols $p.value, "label") <- "Robust Std. Errors Adjusted"

gni_classes_ols

#interactive table for side access 
#datatable(gni_classes_ols, caption = "Regression Results, by GNI Country Classifications")

# write to directory 
write.csv(gni_classes_ols, "output_CSVs/gni_classes_ols.csv")
```


## Visualizing Slopes: plotting multiple regression - by subgroup
```{r echo=FALSE}
viz_gni_class <- ggplot(data = merged_2015, aes(x = spi_comp, 
                                           y = sdg_overall, 
                                           color = income_level_lab)) +
  geom_point(alpha = 0.25, size = 0.75) + 
  # Overall regression line (black)
  geom_smooth(aes(group = 1), 
              method = "lm", 
              linewidth = 0.75, 
              se = FALSE, 
              color = "black") +
  # Group-specific regression lines
  geom_smooth(method = "lm", 
              linewidth = 0.65, 
              se = FALSE) +
  scale_color_manual(
    values = c("High Income Countries" = "#1D6A96", 
               "Upper-Middle Income Countries" = "#4CB5AE",
               "Lower-Middle Income Countries" = "#F3A738",
               "Low Income Countries" = "#C02942")
  ) +
  labs(title = "Relationship between SPI and SDG by World Bank Income Classification",
       x = "Statistical Performance Indicators (SPI)",
       y = "Sustainable Development Goals (SDG)",
       color = "Income Classification") +
  theme_bw() 

viz_gni_class
#ggplotly(viz_gni_class)

# Save to specific folder
ggsave("figures/gni_subgroups_ols.png", viz_gni_class, width = 10, height = 6)
```
[more results TBD]


## Coefficient & Interval Plot
```{r echo=FALSE}
# New fd with SPI coefficients data
spi_plot_data <- data.frame(
  model = c("overall_lm", "high_inc_lm", "upper_mid_lm", "lower_mid_lm", "low_inc_lm"),
  estimate = c(0.286414727883271, 0.355563975838364, 0.174313752024353, 0.382217438772999, 0.169651614020134),
  std.error = c(0.0156271299809294, 0.0170293332032076, 0.0139294904502819, 0.0262707606446246, 0.0441323334102258)
)

# Calculate confidence intervals
spi_plot_data <- spi_plot_data %>%
  mutate(
    CI_lower = estimate - 1.96 * std.error,
    CI_upper = estimate + 1.96 * std.error
  )

# Set model order
model_order <- c("low_inc_lm", "lower_mid_lm", "upper_mid_lm", "high_inc_lm", "overall_lm")
spi_plot_data$model <- factor(spi_plot_data$model, levels = model_order)

# Create the coefficient plot
coef_inter_spi_plot <- ggplot(spi_plot_data, aes(x = estimate, y = model)) +
  geom_point(size = 3, color = "dodgerblue") +
  geom_errorbarh(aes(xmin = CI_lower, xmax = CI_upper), 
                 height = 0.2, 
                 color = "dodgerblue") +
  labs(
    title = "Coefficient Estimates with 95% Confidence Intervals for SPI by Income Group Models",
    x = "Coefficient Estimate for SPI",
    y = NULL
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_x_continuous(limits = c(0, 0.45)) +
  scale_y_discrete(labels = c("low_inc_lm" = "Low Income", 
                              "lower_mid_lm" = "Lower-Middle Income",
                              "upper_mid_lm" = "Upper-Middle Income", 
                              "high_inc_lm" = "High Income",
                              "overall_lm" = "Overall"))

coef_inter_spi_plot

ggsave("figures/coef_inter_spi_plot.png", coef_inter_spi_plot, width = 9, height = 5)
```
