---
title: "Component 1: Multiple OLS, Interactions, Subgroups"
author: "Sevastian Sanchez"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  word_document: default
  html_document: default
---

# All Countries, Preliminary Analysis (SPI x SDGs)
SPI = Statistical Performance Index (0-100, continuous)
SDG = Sustainable Development Goals (0-100, continuous)
DI = EIU Democracy Index/Score (0-10, continuous)
log_gdppc = Log(GDP Per Capita)


```{r setup, include=FALSE}
knitr::opts_chunk$set(
  tidy = TRUE,
  tidy.opts = list(width.cutoff = 60)  # Adjust width as needed
)
```


### LOAD FINAL MERGED CSV 
```{r}
#load final merged df 
merged <- read_csv("data/Main CSV Outputs/merged_final_df.csv")

# refer to 'wrangled/adjust_output.Rmd' to make necessary adjustments 
```

# COMPONENT 1: COMPARING SPI & SCI X VARIABLES

## Preliminary Analysis: Correlation & Naive OLS Models [FINALIZED]

### Correlation Analysis: SPI, SCI, DI & SDG Composite Scores
*H0: Null, there is no relationship*  
*H1: there is a statistically significant relationship between overall SPI and SDG composite scores*

```{r}
# Correlation coefficients & R-squared values for SDG and SPI/SCI/DI

# SDG ~ SPI
correlation_sdg_spi <- cor(merged$sdg_overall, merged$spi_comp, use = "complete.obs")
# R-squared value
R2_sdg_spi <- correlation_sdg_spi^2

# SDG ~ SCI
correlation_sdg_sci <- cor(merged$sdg_overall, merged$sci_overall, use = "complete.obs") 
# R-squared value
R2_sdg_sci <- correlation_sdg_sci^2

# SDG ~ DI
correlation_sdg_di <- cor(merged$sdg_overall, merged$di_score, use = "complete.obs") 
# R-squared value
R2_sdg_di <- correlation_sdg_di^2

# SPI ~ DI 
correlation_spi_di <- cor(merged$spi_comp, merged$di_score, use = "complete.obs")
# R-squared value
R2_spi_di <- correlation_spi_di^2

# SCI ~ DI 
correlation_sci_di <- cor(merged$sci_overall, merged$di_score, use = "complete.obs")
# R-squared value
R2_sci_di <- correlation_sci_di^2

# pasting correlation results
paste("Correlation coefficient:" , correlation_sdg_spi, "(SDG ~ SPI),", correlation_sdg_sci, "(SDG ~ SCI),", correlation_sdg_di, "(SDG ~ DI),", correlation_spi_di, "(SPI ~ DI),", correlation_sci_di, "(SCI ~ DI)")

# pasting R-sq results
paste("R-squared value:", R2_sdg_spi, "(SDG ~ SPI),", R2_sdg_sci, "(SDG ~ SCI),", R2_sdg_di, "(SDG ~ DI),", R2_spi_di, "(SPI ~ DI),", R2_sci_di, "(SCI ~ DI)")
```
SDG ~ SPI: Correlation coefficient: 0.784880, R-squared value: 0.616037
SDG ~ SCI: Correlation coefficient: 0.646503, R-squared value: 0.417966
SDG ~ DI: Correlation coefficient: 0.672644, R-squared value: 0.452450
SPI ~ DI: Correlation coefficient: 0.676171, R-squared value: 0.4572067
SCI ~ DI: Correlation coefficient: 0.477767, R-squared value: 0.2282613

The results demonstrates that SDG performance (SDG) composite scores are most strongly associated with the Statistical Performance Index (SPI), which shows a high correlation coefficient (0.78) and explains about 62% of the variance in SDG scores. Both the Statistical Capacity Index (SCI) and the Democracy Index (DI) also exhibit moderate positive correlations with SDG scores (0.65 and 0.67, respectively), accounting for 42% and 45% of the variance. This could indicate that countries with higher statistical performance and stronger democratic institutions tend to achieve better SDG outcomes, with SPI emerging as the most influential predictor among the indices examined.

Both SPI and SCI are also positively correlated with the Democracy Index, with SPI (0.68) showing a stronger association than SCI (0.48). These findings highlight the interconnectedness of statistical capacity and governance quality, suggesting that improvements in national statistical systems and democratic governance are mutually reinforcing factors in advancing sustainable development.

**The correlation analysis provides a useful overview of the relationships between these indices, but further analysis is needed to understand the causal mechanisms and the impact of these indices on SDG outcomes.**

### NAIVE OLS Models (Component 1): Comparing SPI & SCI Variables on SDG Performance
Finding estimated impact of variables on SDG status prior to adding controls or robust SEs
```{r}
# 1. OLS for SPI and SDG - Overall 
ols_spi_naive <- lm(sdg_overall ~ spi_comp, data = merged)
summary(ols_spi_naive)

# 2. OLS for SCI and SDG - Overall 
ols_sci_naive <- lm(sdg_overall ~ sci_overall, data = merged)
summary(ols_sci_naive)

# 3. Multiple Regression with both SPI and SCI
ols_multiple_naive <- lm(sdg_overall ~ spi_comp + sci_overall, data = merged)
summary(ols_multiple_naive)

# stargazer summary table of models: ols_spi_naive, ols_sci_naive, ols_multiple_naive.
stargazer(
  ols_spi_naive, 
  ols_sci_naive, 
  ols_multiple_naive, 
  type = "html", 
  title = "Naive OLS Models: SPI & SCI x SDG",
  dep.var.caption = "Dependent Variable:",
  dep.var.labels = "SDG Composite Score",
  covariate.labels = c("SPI Composite Score", "SCI Composite Score", "Intercept"),
  column.labels = c("SPI Only", "SCI Only", "SPI + SCI"),  # <-- Model labels at the top
  omit.stat = c("f", "ser"), 
  digits = 4,
  out = "results_csv/naive_ols_models_sdgs_spi_sci.html"  # Save as HTML file
)

```
ols_spi_naive: 0.47806 (p-value < 0.01)  
ols_sci_naive: 0.39081 (p-value < 0.01)  
ols_multiple_naive: spi: 0.28779 (p-value < 0.01); 
                    sci: 0.15311 (p-value < 0.01)

The impact of SCI on SDG and SPI on SDG are statistically significant, in all models. SPI appears to have a greater impact on SDGs compared to that of SCI, regardless of the model. All of this is without controls or accounting multiple time periods of the same subject (i.e., countries).

### NAIVE OLS Models (Component 2): DI variable on SPI & SDG Performance 
Finding estimated impact of DI on SPI and SDG status prior to adding controls or robust SEs
```{r}
# 1. OLS for SPI and DI - Overall
ols_spi_di_naive <- lm(spi_comp ~ di_score, data = merged)
summary(ols_spi_di_naive)

# 2. OLS for SDG and DI - Overall
ols_sdg_di_naive <- lm(sdg_overall ~ di_score, data = merged)
summary(ols_sdg_di_naive)

# stargazer summary table of models: ols_spi_di_naive, ols_sdg_di_naive.
stargazer(
  ols_spi_di_naive, 
  ols_sdg_di_naive, 
  type = "html", 
  title = "Naive OLS Models: DI & SPI/SDG",
  dep.var.caption = "Dependent Variable:",
  dep.var.labels = c("SDG Composite Score", "SPI Composite Score"),
  #covariate.labels = c("di_score", "Intercept"),
  #column.labels = c("SPI Only", "SCI Only", "SPI + SCI"),  # <-- Model labels at the top
  omit.stat = c("f", "ser"), 
  digits = 4,
  out = "results_csv/naive_ols_models_sdgs&spi_di.html"  # Save as HTML file
)

```
*results*
ols_spi_di_naive: 5.0122 (p-value < 0.001)
ols_sdg_di_naive: 3.22301 (p-value < 0.001)

The naive OLS models indicate that the Democracy Index (DI) has a strong positive relationship with both the Statistical Performance Index (SPI) and the Sustainable Development Goals (SDG) composite scores. The coefficients suggest that a one-unit increase in DI is associated with a 5.0122 increase in SPI and a 3.22301 increase in SDG scores, both statistically significant at p < 0.001. This suggests that countries with higher democracy scores tend to have better statistical performance and SDG outcomes.

### Checking for Heteroskedasticity: residual plots [no need to report]
```{r}
#residual plots 
plot(ols_spi_naive, which = 1)  # SDG ~ SPI model
plot(ols_sci_naive, which = 1)  # SDG ~ SCI model
plot(ols_multiple_naive, which = 1)  # SDG ~ SPI + SCI model 
plot(ols_spi_di_naive, which = 1)  # SPI ~ DI model 
plot(ols_sdg_di_naive, which = 1)  # SDG ~ DI model 

# U-shaped residuals detected, suggests non-linearity of x-variable terms. Additional tests reconfirm non-linearity (See Breusch-Pagan Test below). 
```

----------------------------------------------------------------------------------------------------------------

## TEST 1: Pooled OLS & Clustered Robust Standard Errors -- COMPARING MEASURES [DONE]

*Methodology: Pooled OLS Models & Clustered Robust (Huber-White) Standard Errors*
All variables of statistical capacity (SPI & SCI) will be compared on a base pooled OLS regression model structure. Pooled OLS recognizes the panel-like structure allowing to index by specific country and year (country-year). Regular OLS, assumes independence of observations which is not suitable given the repeated waves of country-year over the course of multiple consecutive years. Furthermore, it is customary to apply clustered-group robust standard errors to account for heteroskedasticity and within-unit correlation of countries over many time points. 

*H0: Null, there is no relationship between SPI and SDG composite scores*
*H1: There is a statistically significant relationship between SPI and SDG composite scores*

```{r}
# 1. OLS for SPI and SDG - Overall 
ols_spi <- plm(formula = sdg_overall ~ spi_comp + di_score + log_gdppc + factor(year), 
               model = "pooling", 
               index = c("country_code", "year"),
               data = merged)
summary(ols_spi, vcov = vcovHC(ols_spi, cluster = "group", type = "HC1"))

# 2. OLS for SCI and SDG - Overall 
ols_sci <- plm(formula = sdg_overall ~ sci_overall + di_score + log_gdppc + factor(year), 
               model = "pooling", 
               index = c("country_code", "year"),
               data = merged)
summary(ols_sci, vcov = vcovHC(ols_sci, cluster = "group", type = "HC1"))

# 3. Multiple Regression with both SPI and SCI
ols_multiple <- plm(formula = sdg_overall ~ spi_comp + sci_overall + di_score + log_gdppc + factor(year),
               model = "pooling", 
               index = c("country_code", "year"),
               data = merged)
summary(ols_multiple, vcov = vcovHC(ols_multiple, cluster = "group", type = "HC1"))
```

### Creating dataframe combining summary and Robust SE results [DONE]
```{r echo=FALSE}
# For model statistics extraction 
summary_spi <- summary(ols_spi)
summary_sci <- summary(ols_sci)
summary_multiple <- summary(ols_multiple)

# Extracting robust SEs and coefficients (using coeftest)
rob_stats_spi <- coeftest(ols_spi, vcov = vcovHC(ols_spi, cluster = "group", type = "HC1"))
rob_stats_sci <- coeftest(ols_sci, vcov = vcovHC(ols_sci, cluster = "group", type = "HC1"))
rob_stats_multiple <- coeftest(ols_multiple, vcov = vcovHC(ols_multiple, cluster = "group", type = "HC1"))

# Stargazer Table
stargazer(ols_spi, ols_sci, ols_multiple,
          se = list(rob_stats_spi[,2], rob_stats_sci[,2], rob_stats_multiple[,2]),
          title = "Pooled OLS Models with Robust Standard Errors",
          align = TRUE,
          dep.var.labels = "SDG Overall Performance",
          covariate.labels = c("SPI Composite", "SCI Overall", "Democracy Index", 
                               "Log GDP per Capita", "Year 2008", "Year 2010", "Year 2011", 
                               "Year 2012", "Year 2013", "Year 2014", "Year 2015", "Year 2016", 
                               "Year 2017", "Year 2018", "Year 2019", "Year 2020", "Year 2021", 
                               "Year 2022", "Year 2023"),
          column.labels = c("M1: ols_spi", "M2: ols_sci", "M3: ols_multiple"),
          keep.stat = c("n", "rsq", "adj.rsq"),
          type = "html", 
          out = "results_csv/pooled_ols_models_spi_sci_both.html") #saved as html

# CREATING CSV OF MODEL'S STATISTICS TO SAVE 
#SPI Statistics DF
spi_df <- data.frame(
  model = rep("M1: ols_spi", nrow(rob_stats_spi)),
  term = rownames(rob_stats_spi),
  estimate = rob_stats_spi[, 1],
  std.error = rob_stats_spi[, 2],
  t.statistic = rob_stats_spi[, 3],
  p.value = rob_stats_spi[, 4],
  residual.SE = rep(sqrt(sum(residuals(ols_spi)^2) / ols_spi$df.residual), nrow(rob_stats_spi)),
  r.squared = rep(as.numeric(summary_spi$r.squared["rsq"]), nrow(rob_stats_spi)),
  adj.r.squared = rep(as.numeric(summary_spi$r.squared["adjrsq"]), nrow(rob_stats_spi)),
  row.names = NULL
)

#SCI Statistics DF
sci_df <- data.frame(
  model = rep("M2: ols_sci", nrow(rob_stats_sci)),
  term = rownames(rob_stats_sci),
  estimate = rob_stats_sci[, 1],
  std.error = rob_stats_sci[, 2],
  t.statistic = rob_stats_sci[, 3],
  p.value = rob_stats_sci[, 4],
  residual.SE = rep(sqrt(sum(residuals(ols_sci)^2) / ols_sci$df.residual), nrow(rob_stats_sci)),
  r.squared = rep(as.numeric(summary_sci$r.squared["rsq"]), nrow(rob_stats_sci)),
  adj.r.squared = rep(as.numeric(summary_sci$r.squared["adjrsq"]), nrow(rob_stats_sci)),
  row.names = NULL
)

#Combined Mod Statistics DF
multiple_df <- data.frame(
  model = "M3: ols_multiple",
  term = rownames(rob_stats_multiple),
  estimate = rob_stats_multiple[, 1],
  std.error = rob_stats_multiple[, 2],
  t.statistic = rob_stats_multiple[, 3],
  p.value = rob_stats_multiple[, 4],
  residual.SE = rep(sqrt(sum(residuals(ols_multiple)^2) / ols_multiple$df.residual), nrow(rob_stats_multiple)),
  r.squared = rep(as.numeric(summary_sci$r.squared["rsq"]), nrow(rob_stats_multiple)),
  adj.r.squared = rep(as.numeric(summary_sci$r.squared["adjrsq"]), nrow(rob_stats_multiple)),
  row.names = NULL
)

# Bind all together into one tidy dataframe
robust_mods_df <- bind_rows(spi_df, sci_df, multiple_df)

# Attributes under column names 
attr(robust_mods_df$std.error, "label") <- "Robust Std. Errors Adjusted"
attr(robust_mods_df$t.statistic, "label") <- "Robust Std. Errors Adjusted"
attr(robust_mods_df$p.value, "label") <- "Robust Std. Errors Adjusted"

#save to results_csv folder
write.csv(robust_mods_df, file = "results_csv/ols_mods_results.csv")

# View the result
print(robust_mods_df)

# DT for readability
#datatable(robust_mods_df, options = list(pageLength = 10, autoWidth = TRUE))

```
The results of the OLS models with robust standard errors indicate that both SPI and SCI have a statistically significant positive relationship with SDG composite scores. The p-values for both SPI and SCI are less than 0.001, indicating strong evidence against the null hypothesis of no relationship for either model. Holding all else constant (log GDP per capita, democracy score and year), SPI and SCI exhibit positive moderate and statistically significant relationships with SDG status.

ols_spi: 0.28735 (p-value < 0.001)*** 
ols_sci: 0.237633 (p-value < 0.001)*** 
ols_multiple: 
  spi: 0.124233 (p-value < 0.05)*
  sci: 0.138766 (p-value < 0.01)**

When compared in separate models, SPI has a greater impact on SDG status (0.28735) than SCI (0.237633). This suggests that a one-unit increase in SPI is associated with a larger improvement in SDG outcomes compared to a one-unit increase in SCI, holding all controls constant. 

Interestingly, the opposite holds true in a multiple regression model containing both SPI and SCI. SPI's impact on SDG status (0.124233) (net of SPI) is less than that of SCI's (0.138766) (net of SCI), holding all controls constant. When together, the coefficients represent the unique impact of each predictor variable (measures of statistical capacity) on SDG status, net of all other variables.

Model 1 (ols_spi) does not control for SCI and model 2 (ols_sci) does not control for spi -- this is okay. SPI is the predecessor of the SCI, sharing/data overlap, and so it is expected to have significant statistical correlation (multicollinearity). This is possibly what explains the reduction of both regression coefficients in model 3: 0.28735 to 0.124233 for SPI (__% decrease); and from 0.237633 to 0.138766 for SCI (__% decrease). This indicates that both variables capture much of the same underlying relationship with SDG performance.

However, the fact that both SPI and SCI remain significant when included together (model 3), although SCI less so than SPI, with a high adjusted R-sq (0.741525), which suggests they capture different dimensions of statistical capacity that independently contribute to SDG status.

### Checking for Multicolinearity: VIF of SPI & SCI [DONE]
```{r}
# Check correlation between SPI and SCI
cor(merged$spi_comp, merged$sci_overall, use = "complete.obs")

# Check VIF (Variance Inflation Factor) in Model 3
vif(ols_multiple)

#make into Datatable 
vif_vals <- vif(ols_multiple)   # returns a named vector
tidy_vif <- enframe(vif_vals, name = "term", value = "vif")
print(tidy_vif)
```

**colinearity:** The correlation between SCI and SPI is about 0.8277. When placed within the same model, SCI inflated the standard error of SPI from 0.013079 to 0.027054. SCI had a similar reaction from the SPI with its standard error increasing from 0.0095864 to 0.024096.

**VIF:** Such multicollinearity is moderately reflected in the VIF test which accounts for all x variables in the model instead of just the two measures of statistical capacity (SCI & SPI).

_VIF Results:_
  term          vif    Df    GVIF^(1/(2*Df))
spi_comp     4.316894  1        2.077714
sci_overall  3.754613  1        1.937682
di_score     1.598314  1        1.264244
log_gdppc    1.485085  1        1.218641
factor(year) 1.302733  4        1.033611 

Overall there reveals no severe multicollinearity (all GVIF < 5). There is moderate correlation between statistical capacity measures (spi_comp and sci_overall) with SPI moderately inflated by a factor of 4.32 and SCI inflated by a factor of  3.75. Nevertheless, it is acceptable to include both in the same model as doing so will not severely impact estimates with both factors less than 5.0. Even so, there are significant limitations in either model that warrant strong consideration, including sample size, and longitudinal suitability. All other variables show minimal multicollinearity concerns.

### Checking for Heteroskedasticity: Breusch-Pagan Test [DONE]
This validates the need for integrating robust standard errors in our models
```{r}
#Breusch-Pagan tests 
bptest(ols_spi)
bptest(ols_sci)
bptest(ols_multiple)

#make into objects 
bp_spi <- bptest(ols_spi)
bp_sci <- bptest(ols_sci)
bp_multiple <- bptest(ols_multiple)

# combine for data frame 
bp_tests <- list(
  ols_spi = bp_spi,
  ols_sci = bp_sci,
  ols_multiple = bp_multiple
)

# Tidy all tests and add a "model" column
df_bptests <- bp_tests %>% 
  map_df(~ tidy(.x), .id = "model")

df_bptests

write.table(df_bptests, file = 'results_csv/df_bptests_heterosked.csv', row.names=F, sep = ",")
```
Model:         BP statistic      p-value
ols_spi           207.         = 7.05e-39       
ols_sci           86.6         = 4.22e-12
ols_multiple      31.1         = 1.33e- 4 

The Breusch-Pagan Test was applied to test to see whether residuals are constant across observations, which signals unaccounted non-linear relationships, especially with macro factors such as GDP Per Capita and Population in the models. This is important because Ordinary Least Squares models assume constant error variance. In such a complex world of diverse cultural and ever-changing political structures across almost 200 countries, cross-national data, especially in development, is rarely ever linear. Accordingly, this test evaluates the extent of such non-linearity among specified predictors. 

As such, results indicate strong evidence of heteroskedasticity in all three models. The small p-values in all models indicates that the variance of residuals are not constant across observations in all three models. This reinforces the motivation behind applying robust standard errors, which have been integrated to all OLS models. Without Robust SEs, there is a risk of inflated t-statistics, leading to false significance and misinterpretation of results.

Despite the improvement from 206.5 (SPI) and 86.6 (SCI) to 31.1 (Both), there still remains statically significant heteroskedasticity in the combined model. Both statistical capacity measures create a better-specified model (ols_multiple), though not enough to eliminate heteroskedasticity entirely.

### Missing Data Structure & Interpretations [DONE]
**Systematic, non-random missing data pattern:** SPI has near complete country data coverage (165 out of 168 countries with an SDG score), but with a stubborn temporal limitation (2016-2023). On the other hand, SCI has longer temporal coverage (2004-2020) but lacks reporting on high-income countries focusing primarily on the developing world (123 out of 168 countries with an SDG score).

### AIC/BIC Checking Fit [DONE]
*H0: Null, SCI model or Combined model > SPI model*
*H1: SPI model > SCI model & combined model*
```{r}
# switching to lm for AIC & BIC tests [POLS]
ols_spi_lm <- lm(sdg_overall ~ spi_comp + di_score + log_gdppc + factor(year), data = merged)
ols_sci_lm <- lm(sdg_overall ~ sci_overall + di_score + log_gdppc + factor(year), data = merged)
ols_multiple_lm <- lm(sdg_overall ~ spi_comp + sci_overall + di_score + log_gdppc + factor(year), data = merged)

# Compare all three models with AIC
AIC(ols_spi_lm, ols_sci_lm, ols_multiple_lm)
# Compare all three models with BIC
BIC(ols_spi_lm, ols_sci_lm, ols_multiple_lm)

# Switching to lm for AIC & BIC tests [FE]
fe_spi_lm <- lm(sdg_overall ~ spi_comp + di_score + log_gdppc + factor(year) + factor(country_code), data = merged)
fe_sci_lm <- lm(sdg_overall ~ sci_overall + di_score + log_gdppc + factor(year) + factor(country_code), data = merged)
fe_multiple_lm <- lm(sdg_overall ~ spi_comp + sci_overall + di_score + log_gdppc + factor(year) + factor(country_code), data = merged)

# Compare all three models with AIC
AIC(fe_spi_lm, fe_sci_lm, fe_multiple_lm)
# Compare all three models with BIC
BIC(fe_spi_lm, fe_sci_lm, fe_multiple_lm)

# INTO DATAFRAME 
aic_vals <- c(
  AIC(ols_spi_lm),
  AIC(ols_sci_lm),
  AIC(ols_multiple_lm),
  AIC(fe_spi_lm),
  AIC(fe_sci_lm),
  AIC(fe_multiple_lm)
)

bic_vals <- c(
  BIC(ols_spi_lm),
  BIC(ols_sci_lm),
  BIC(ols_multiple_lm),
  BIC(fe_spi_lm),
  BIC(fe_sci_lm),
  BIC(fe_multiple_lm)
)

# Model names
model_names <- c("ols_spi", "ols_sci", "ols_multiple", #POLS
                 "fe_spi", "fe_sci", "fe_multiple") #FE

# Combine into a dataframe
aic_bic_c1_results <- data.frame(
  model = model_names,
  AIC = aic_vals,
  BIC = bic_vals
)

print(aic_bic_c1_results)

# saving to results_csv
write.csv(aic_bic_c1_results, file = "results_csv/aic_bic_c1_results.csv")
```
**AIC/BIC Results**
     model          AIC       BIC
m1: ols_spi       7382.060  7443.496
m2: ols_sci       9003.178  9093.672
m3: ols_multiple  3292.001  3335.405
m4: fe_spi        2588.303  3443.282
m5: fe_sci        4337.547  5045.529
m6: fe_multiple   1073.202  1607.066
note: all models have different number of observations, ols_multiple containing the least.

**Adjusted R-squares** 
m1: ols_spi:      0.7757 [best fit]
m2: ols_sci:      0.74152
m3: ols_multiple: 0.75683
m4: fe_spi        
m5: fe_sci        
m6: fe_multiple
### Selecting Best Model [DONE]
**Best fit: ols_spi (Adj Rsq: 0.7725) (AIC/BIC: 7382.060, 7443.496) (n=1082)**
To determine which predictor (i.e., SPI or SCI) is stronger –also considering if they’re stronger together (ols_multiple)– this investigation considers (a) descriptive statistics (i.e., number of observations); (b) adjusted R2 estimates; and (c) AIC/BIC model scores. These measures are compared across models that sustain the same controls, however, statistical checks are weighted against frequency of observations, given anticipated differences in the number of years and mis-alignment of particular start to end year periods. 

### Visual Analysis of Fit: SCI & SPI x SDG
```{r echo=FALSE}
#define regression line colors
spi_line <- "steelblue4"
sci_line <- "darkgoldenrod"

# Creating scatterplot with both SPI and SCI on the same plot
Compare_fit <- ggplot(merged, aes(x = spi_comp, y = sdg_overall))+
  geom_smooth(aes(x = spi_comp, y = sdg_overall), 
              color = spi_line, 
              method = "lm", 
              linewidth = 0.75, 
              se = FALSE)+ # Regression line SPI
  geom_smooth(aes(x = sci_overall, y = sdg_overall), 
              color = sci_line, 
              method = "lm", 
              linewidth = 0.75, 
              se = FALSE)+ # Regression line for SCI
  geom_point(aes(color = "spi_comp"), alpha=0.50, size = 0.5)+ # Scatter plot for SPI
  geom_point(aes(x = sci_overall, y = sdg_overall, color = "sci_overall"), 
             alpha=0.5, size = 0.5)+ # Add SCI points w/different color
  scale_color_manual(values = c("spi_comp" = "steelblue2", 
                                "sci_overall" = "darkgoldenrod2")) +
  labs(title = "Comparing SPI & SCI Measures Against SDG Index",
       x = "SPI & SCI Scores (0-100)",
       y = "SDG Composite Scores (0-100)",
       color = "Measure:"
       ) + 
  theme_minimal() +
  theme(axis.title = element_text(size = 12)) + # size for both axis titles
  theme(legend.position = "bottom",
        legend.box = "horizontal",
        legend.title = element_text(size = 10), # size for legend title 
        legend.text = element_text(size = 10), # size for both legend lables
        plot.title = element_text(hjust= 0.4, size = 12, face = "bold")) # title size and position

# Print the plot
Compare_fit

#make interactive
#ggplotly(Compare_fit)

# Save to specific folder
ggsave("figures/spi_sci_plot.png", Compare_fit, width = 8, height = 6)
```
Note. The SPI regression line is expected to appear higher in terms of SDG Score compared the SCI model because SPI countries include higher-income countries. As previously mentioned, the SCI soley focuses on lower to upper-middle income countries (146 countries over 17 years). 


#### Selecting variables and filtering years +2015
```{r}
# Wrangling for analysis and multicollinearity concerns 
merged_2015 <- merged %>% 
  filter(year >= 2016) %>% 
  # Selecting relevant variables for analysis 
  dplyr::select(country_code, year, sdg_overall, spi_comp, di_score, log_gdppc, income_level, regime_type_2, regime_type_4, aut_ep, dem_ep, regch_event)
```

### Test 3: Checking for Interactions
modeling how the effect of SPI on SDG performance depends on one/any of the following moderators:
  - income level (GNI Classification)
  - regime type (RoW Binary & Categorical)
  - democracy index (di_score)
- Is there a need for subgroup analysis, and if so, by what kind of group? 
- Possible Moderators: GNI Classification (income_level), regime_type_2, regime_type_4, di_score

#### Recoding for Interactions
```{r}
# Recode to dummy variables
merged_2015 <- merged_2015 %>% 
  # Recoding income_level, split income_level into dummy variables using case_when()
  mutate(income_level_recoded = case_when(
    income_level == "L" ~ 0, # Low-Income
    income_level == "LM" ~ 1, # Lower-Middle-Income
    income_level == "UM" ~ 2, # Upper-Middle-Income
    income_level == "H" ~ 3, # High-Income
    TRUE ~ NA_real_  # Handle any other cases
  )) %>% 
  mutate(income_level_recoded = as.factor(income_level_recoded)) %>% 
  # recoding/factorizing regime_type_2: 0 = Autocracy; 1 = Democracy 
  mutate(regime_type_binary = as.factor(regime_type_2)) %>% 
  # recoding regime_type_4: 0 = Closed Autocracy; 1 = Electoral Autocracy; 2 = Electoral Democracy; 3 = Full Democracy
  mutate(regime_type_categ = as.factor(regime_type_4)) %>% 
  mutate(aut_ep = as.factor(aut_ep), # autocratization episode
         dem_ep = as.factor(dem_ep)) # democratization episode

### HYPOTHESES ###
# H0: NUll, the impact of SPI on SDG Performance does NOT vary depending on Z [income_level_recoded, regime_type_binary, regime_type_categ, di_score]
# H1: The impact of SPI on SDG Performance varies depending on Z [income_level_recoded, regime_type_binary, regime_type_categ, di_score]

# Interaction 1: 
# HA: The impact of SPI on SDG performance varies depending on GNI Classification (income_level_recoded: 1 = Low; 2 = Lower-Middle; 3 = Upper-Middle; 4 = High)
spi_x_inc_lvl <- plm(sdg_overall ~ cen_spi_comp*factor(income_level_recoded) + cen_di_score +
                       cen_log_gdppc + I(cen_log_gdppc^2) + factor(year), 
                     model = "pooling", 
                     index = c("country_code", "year"),
                     data = merged_2015)
summary(spi_x_inc_lvl, vcov = vcovHC(spi_x_inc_lvl, cluster = "group", type = "HC1"))


# Interaction 2: 
# HA: The impact of SPI on SDG performance varies depending on Regime Type (Binary: 0 = Autocracy; 1 = Democracy)
spi_x_reg_binary <- plm(sdg_overall ~ cen_spi_comp*factor(regime_type_binary) + cen_di_score +
                          cen_log_gdppc + I(cen_log_gdppc^2) + factor(year), 
                        model = "pooling", 
                        index = c("country_code", "year"),
                        data = merged_2015)
summary(spi_x_reg_binary, vcov = vcovHC(spi_x_reg_binary, cluster = "group", type = "HC1"))


# Interaction 3: 
# HA: The impact of SPI on SDG performance varies depending on Regime Type (Categorical: 0 = Closed Autocracy; 1 = Electoral Autocracy; 2 = Electoral Democracy; 3 = Full Democracy)
spi_x_reg_categ <- plm(sdg_overall ~ cen_spi_comp*factor(regime_type_categ) + cen_di_score + 
                         cen_log_gdppc + I(cen_log_gdppc^2) + factor(year), 
                       model = "pooling", 
                       index = c("country_code", "year"),
                       data = merged_2015)
summary(spi_x_reg_categ, vcov = vcovHC(spi_x_reg_categ, cluster = "group", type = "HC1"))


# Interaction 4: 
# HA: The impact of SPI on SDG performance varies depending on Democracy Score (cen_di_score: 0-1, continuous)
spi_x_di_score <- plm(sdg_overall ~ cen_spi_comp*cen_di_score + cen_log_gdppc + I(cen_log_gdppc^2) +
                        factor(year), 
                      model = "pooling", 
                      index = c("country_code", "year"),
                      data = merged_2015)
summary(spi_x_di_score, vcov = vcovHC(spi_x_di_score, cluster = "group", type = "HC1"))

# Interaction 5
# HA: The impact of SPI on SDG performance varies depending on Regime Change Status/Direction
spi_x_reg_eps <- plm(sdg_overall ~ cen_spi_comp*aut_ep + cen_spi_comp*dem_ep +
                     cen_log_gdppc + I(cen_log_gdppc^2) + factor(year), 
                   model = "pooling", 
                   index = c("country_code", "year"),
                   data = merged_2015)
summary(spi_x_reg_eps, vcov = vcovHC(spi_x_reg_eps, cluster = "group", type = "HC1"))

# Final Model 
final_model <- plm(sdg_overall ~ cen_spi_comp*factor(income_level_recoded) + cen_spi_comp*cen_di_score + cen_log_gdppc + I(cen_log_gdppc^2) + factor(year), 
                   model = "within", 
                   index = c("country_code", "year"),
                   data = merged_2015)
summary(final_model, vcov = vcovHC(final_model, cluster = "group", type = "HC1"))
```
*Interaction 1: GNI Income Classification:* 
*HA: The impact of SPI on SDG performance varies depending on GNI Classification (income_level_recoded: 1 = Low; 2 = Lower-Middle; 3 = Upper-Middle; 4 = High)*
[results in doc]...

*Interaction 2: Regime Type (Binary):*
*HA: The impact of SPI on SDG performance varies depending on Regime Type (Binary: 0 = Autocracy; 1 = Democracy)*
...

*Interaction 3: Regime Type (Categorical):*
*HA: The impact of SPI on SDG performance varies depending on Regime Type (Categorical: 0 = Closed Autocracy; 1 = Electoral Autocracy; 2 = Electoral Democracy; 3 = Full Democracy)*
...

*Interaction 4: Democracy Index (Continuous):*
*HA: The impact of SPI on SDG performance varies depending on Democracy Score (cen_di_score: 0-1, continuous)*
...

*Interaction 5: Regime Change Status/Direction:*
*HA: The impact of SPI on SDG performance varies depending on Regime Change Status/Direction*
Results: 


#### Interactions DF 
```{r}
# Create a helper function for tidying plm models with robust SEs
tidy_plm_robust <- function(model, model_name) {
  tidy(model, 
       conf.int = TRUE, 
       vcov. = vcovHC(model, cluster = "group", type = "HC1")) %>%
    mutate(model = model_name,
           n_obs = n_obs)
}

# Enhanced helper function
tidy_plm_robust <- function(model, model_name) {
  tidy_coef <- tidy(model, 
                    conf.int = TRUE, 
                    vcov. = vcovHC(model, cluster = "group", type = "HC1")) %>%
    mutate(model = model_name)
  
  # Extract model statistics
  model_summary <- summary(model)
  tidy_coef %>%
    mutate(
      adj_r_squared = model_summary$r.squared["adjrsq"]
    )
}

# Apply tidy_plm_robust() function to all models
tidy_spi_x_inc_lvl    <- tidy_plm_robust(spi_x_inc_lvl, "Moderator: SPI x Income Level")
tidy_spi_x_reg_binary <- tidy_plm_robust(spi_x_reg_binary, "Moderator: SPI x Regime Binary")
tidy_spi_x_reg_categ  <- tidy_plm_robust(spi_x_reg_categ, "Moderator: SPI x Regime Categ")
tidy_spi_x_di_score   <- tidy_plm_robust(spi_x_di_score, "Moderator: SPI x DI Score")
tidy_spi_x_reg_eps   <- tidy_plm_robust(spi_x_reg_eps, "Moderator: SPI x Regime Change")

model_n_obs <- tibble(
  model = c("Moderator: SPI x Income Level", "Moderator: SPI x Regime Binary", 
            "Moderator: SPI x Regime Categ", "Moderator: SPI x DI Score", "Moderator: SPI x Regime Change"),
  n_obs = c(nobs(spi_x_inc_lvl), nobs(spi_x_reg_binary),
            nobs(spi_x_reg_categ), nobs(spi_x_di_score), nobs(spi_x_reg_eps))
)

# Combine all tidy data frames into one
all_models_tidy <- bind_rows(tidy_spi_x_inc_lvl, 
                             tidy_spi_x_reg_binary, 
                             tidy_spi_x_reg_categ, 
                             tidy_spi_x_di_score, 
                             tidy_spi_x_reg_eps) %>%
  left_join(model_n_obs, by = "model") %>% 
  select(model, term, estimate, std.error, p.value, adj_r_squared, n_obs, everything()) %>%
  arrange(model, term)

# Save the tidy data frame to a CSV file
write_csv(all_models_tidy, "results_csv/interaction_models.csv")


# extracting robust standard errors for each interaction model
rob_se_spi_x_inc_lvl <- coeftest(spi_x_inc_lvl, vcov = vcovHC(spi_x_inc_lvl, cluster = "group", type = "HC1"))
rob_se_spi_x_reg_binary <- coeftest(spi_x_reg_binary, vcov = vcovHC(spi_x_reg_binary, cluster = "group", type = "HC1"))
rob_se_spi_x_reg_categ <- coeftest(spi_x_reg_categ, vcov = vcovHC(spi_x_reg_categ, cluster = "group", type = "HC1"))
#rob_se_spi_x_di_score <- coeftest(spi_x_di_score, vcov = vcovHC(spi_x_di_score, cluster = "group", type = "HC1"))
rob_se_spi_x_reg_eps <- coeftest(spi_x_reg_eps, vcov = vcovHC(spi_x_reg_eps, cluster = "group", type = "HC1"))

# Create a list of robust standard errors for stargazer
robust_se_list <- list(
  rob_se_spi_x_inc_lvl[, 2], 
  rob_se_spi_x_reg_binary[, 2], 
  rob_se_spi_x_reg_categ[, 2], 
  #rob_se_spi_x_di_score[, 2] #,
  rob_se_spi_x_reg_eps[, 2]
  )
          
stargazer(
  spi_x_inc_lvl, spi_x_reg_binary, spi_x_reg_categ, #spi_x_di_score,
  spi_x_reg_eps,
  se = robust_se_list,
  type = "html",
  out = "figures/pooled_ols_interactions.html",
  title = "Pooled OLS Interaction Models",
  align = TRUE,
  column.labels = c("Income Level", "Regime Binary", "Regime Categ", "Regime Change Episode"),
  dep.var.labels = "SDG Overall",
  omit = "factor\\(year\\)",  # Omits year fixed effects from display
  model.names = FALSE
)

```


## TEST 3b: WB GNI Classifications: income_level ("H", "UM", "LM", "L") 
#### Disaggregated/Grouped by Development Status:
Make 4 regression models and then put them all together in a table to compare the slopes and R-sq values.
```{r}
# 1. Overall model (all countries)
overall_lm <- lm(sdg_overall ~ spi_comp + di_score + log_gdppc + population + factor(year),
                        data = merged_2015)
#summary(overall_lm)
coeftest(overall_lm, vcov = vcovHC(overall_lm, type = "HC1")) #Robust SE

# 2. High income countries
high_inc_lm <- lm(sdg_overall ~ spi_comp + di_score + log_gdppc + population + factor(year),
                        data = merged_2015 %>% 
                          filter(income_level == "H"))
#summary(high_inc_lm)
coeftest(high_inc_lm, vcov = vcovHC(high_inc_lm, type = "HC1")) #Robust SE

# 3. Upper-middle income countries
upper_mid_lm <- lm(sdg_overall ~ spi_comp + di_score + log_gdppc + population + factor(year),
                         data = merged_2015 %>% 
                           filter(income_level == "UM"))
#summary(upper_mid_lm)
coeftest(upper_mid_lm, vcov = vcovHC(upper_mid_lm, type = "HC1")) #Robust SE

# 4. Lower-middle income countries
lower_mid_lm <- lm(sdg_overall ~ spi_comp + di_score + log_gdppc + population + factor(year),
                         data = merged_2015 %>% 
                           filter(income_level == "LM"))
#summary(lower_mid_lm)
coeftest(lower_mid_lm, vcov = vcovHC(lower_mid_lm, type = "HC1")) #Robust SE

# 5. Low income countries
low_inc_lm <- lm(sdg_overall ~ spi_comp + di_score + log_gdppc + population + factor(year),
                       data = merged_2015 %>% 
                         filter(income_level == "L"))
#summary(low_inc_lm)
coeftest(low_inc_lm, vcov = vcovHC(low_inc_lm, type = "HC1")) #Robust SE
```


### GNI Classifications DF
```{r echo=FALSE}
# 1. Overall model
overall_ct <- coeftest(overall_lm, vcov = vcovHC(overall_lm, type = "HC1"))
overall_df <- data.frame(
  model = "overall_lm",
  term = rownames(overall_ct),
  estimate = overall_ct[, "Estimate"],
  std.error = overall_ct[, "Std. Error"],
  t.statistic = overall_ct[, "t value"],
  p.value = overall_ct[, "Pr(>|t|)"],
  n = nobs(overall_lm)
)

# 2. High income countries
high_inc_ct <- coeftest(high_inc_lm, vcov = vcovHC(high_inc_lm, type = "HC1"))
high_inc_df <- data.frame(
  model = "high_inc_lm",
  term = rownames(high_inc_ct),
  estimate = high_inc_ct[, "Estimate"],
  std.error = high_inc_ct[, "Std. Error"],
  t.statistic = high_inc_ct[, "t value"],
  p.value = high_inc_ct[, "Pr(>|t|)"],
  n = nobs(high_inc_lm)
)

# 3. Upper-middle income countries
upper_mid_ct <- coeftest(upper_mid_lm, vcov = vcovHC(upper_mid_lm, type = "HC1"))
upper_mid_df <- data.frame(
  model = "upper_mid_lm",
  term = rownames(upper_mid_ct),
  estimate = upper_mid_ct[, "Estimate"],
  std.error = upper_mid_ct[, "Std. Error"],
  t.statistic = upper_mid_ct[, "t value"],
  p.value = upper_mid_ct[, "Pr(>|t|)"],
  n = nobs(upper_mid_lm)
)

# 4. Lower-middle income countries
lower_mid_ct <- coeftest(lower_mid_lm, vcov = vcovHC(lower_mid_lm, type = "HC1"))
lower_mid_df <- data.frame(
  model = "lower_mid_lm",
  term = rownames(lower_mid_ct),
  estimate = lower_mid_ct[, "Estimate"],
  std.error = lower_mid_ct[, "Std. Error"],
  t.statistic = lower_mid_ct[, "t value"],
  p.value = lower_mid_ct[, "Pr(>|t|)"],
  n = nobs(lower_mid_lm)
)

# 5. Low income countries
low_inc_ct <- coeftest(low_inc_lm, vcov = vcovHC(low_inc_lm, type = "HC1"))
low_inc_df <- data.frame(
  model = "low_inc_lm",
  term = rownames(low_inc_ct),
  estimate = low_inc_ct[, "Estimate"],
  std.error = low_inc_ct[, "Std. Error"],
  t.statistic = low_inc_ct[, "t value"],
  p.value = low_inc_ct[, "Pr(>|t|)"],
  n = nobs(low_inc_lm)
)

# Combine all results
gni_classes_ols <- bind_rows(
  overall_df,
  high_inc_df,
  upper_mid_df,
  lower_mid_df,
  low_inc_df
)

attr(gni_classes_ols $std.error, "label") <- "Robust Std. Errors Adjusted"
attr(gni_classes_ols $t.statistic, "label") <- "Robust Std. Errors Adjusted"
attr(gni_classes_ols $p.value, "label") <- "Robust Std. Errors Adjusted"

gni_classes_ols

#interactive table for side access 
#datatable(gni_classes_ols, caption = "Regression Results, by GNI Country Classifications")

# write to directory 
write.csv(gni_classes_ols, "results_csv/gni_classes_ols.csv")
```


### Visualizing Slopes: plotting multiple regression - by subgroup
```{r echo=FALSE}
viz_gni_class <- ggplot(data = merged_2015, aes(x = spi_comp, 
                                           y = sdg_overall, 
                                           color = income_level_lab)) +
  geom_point(alpha = 0.25, size = 0.75) + 
  # Overall regression line (black)
  geom_smooth(aes(group = 1), 
              method = "lm", 
              linewidth = 0.75, 
              se = FALSE, 
              color = "black") +
  # Group-specific regression lines
  geom_smooth(method = "lm", 
              linewidth = 0.65, 
              se = FALSE) +
  scale_color_manual(
    values = c("High Income Countries" = "#1D6A96", 
               "Upper-Middle Income Countries" = "#4CB5AE",
               "Lower-Middle Income Countries" = "#F3A738",
               "Low Income Countries" = "#C02942")
  ) +
  labs(title = "Relationship between SPI and SDG by World Bank Income Classification",
       x = "Statistical Performance Indicators (SPI)",
       y = "Sustainable Development Goals (SDG)",
       color = "Income Classification") +
  theme_bw() 

viz_gni_class
#ggplotly(viz_gni_class)

# Save to specific folder
ggsave("figures/gni_subgroups_ols.png", viz_gni_class, width = 10, height = 6)
```
[more results TBD]


#### Coefficient & Interval Plot
```{r echo=FALSE}
# New fd with SPI coefficients data
spi_plot_data <- data.frame(
  model = c("overall_lm", "high_inc_lm", "upper_mid_lm", "lower_mid_lm", "low_inc_lm"),
  estimate = c(0.286414727883271, 0.355563975838364, 0.174313752024353, 0.382217438772999, 0.169651614020134),
  std.error = c(0.0156271299809294, 0.0170293332032076, 0.0139294904502819, 0.0262707606446246, 0.0441323334102258)
)

# Calculate confidence intervals
spi_plot_data <- spi_plot_data %>%
  mutate(
    CI_lower = estimate - 1.96 * std.error,
    CI_upper = estimate + 1.96 * std.error
  )

# Set model order
model_order <- c("low_inc_lm", "lower_mid_lm", "upper_mid_lm", "high_inc_lm", "overall_lm")
spi_plot_data$model <- factor(spi_plot_data$model, levels = model_order)

# Create the coefficient plot
coef_inter_spi_plot <- ggplot(spi_plot_data, aes(x = estimate, y = model)) +
  geom_point(size = 3, color = "dodgerblue") +
  geom_errorbarh(aes(xmin = CI_lower, xmax = CI_upper), 
                 height = 0.2, 
                 color = "dodgerblue") +
  labs(
    title = "Coefficient Estimates with 95% Confidence Intervals for SPI by Income Group Models",
    x = "Coefficient Estimate for SPI",
    y = NULL
  ) +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5)) +
  scale_x_continuous(limits = c(0, 0.45)) +
  scale_y_discrete(labels = c("low_inc_lm" = "Low Income", 
                              "lower_mid_lm" = "Lower-Middle Income",
                              "upper_mid_lm" = "Upper-Middle Income", 
                              "high_inc_lm" = "High Income",
                              "overall_lm" = "Overall"))

coef_inter_spi_plot

ggsave("figures/coef_inter_spi_plot.png", coef_inter_spi_plot, width = 9, height = 5)
```
